{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_ENDPOINT = \"http://localhost:11434/v1\"\n",
    "MODEL_NAME = \"qwen3:4b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=OLLAMA_ENDPOINT,\n",
    "    api_key=\"ollama\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_ollama(query):\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen3:4b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": query}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(ask_ollama(\"what is the weather in new orleans today?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api call to get location data\n",
    "!curl \"https://geocoding-api.open-meteo.com/v1/search?name=new%20orleans&count=1&language=en&format=json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api call to get weather data\n",
    "!curl \"https://api.open-meteo.com/v1/forecast?latitude={29.95465}&longitude={-90.07507}&current_weather=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(city_name):\n",
    "    \"\"\"Get latitude and longitude for a city\"\"\"\n",
    "    try: \n",
    "        encoded_city = city_name.replace(' ', '%20')\n",
    "        url = f\"https://geocoding-api.open-meteo.com/v1/search?name={encoded_city}&count=1&language=en&format=json\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        if not data.get('results'):\n",
    "            return None, None, None\n",
    "        result = data['results'][0]\n",
    "        return (result['latitude'], result['longitude'], result['name'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting coordinates: {e}\")\n",
    "        return None, None, None\n",
    "    \n",
    "def get_weather(latitude, longitude):\n",
    "    \"\"\"Get weather information for a city\"\"\"\n",
    "    try:\n",
    "        url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current_weather=true\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting weather: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT1 = \"\"\"\n",
    "You are a heplful AI assitant.\n",
    "You have access to the following functions to assist the user.\n",
    "\n",
    "You SHOULD NOT include any other text in your response if you are calling a function.\n",
    "If you have enough information to answer the user's request or the request does not require a function call, respond directly to the user in plain text.\n",
    "\n",
    "Here are the available functions:\n",
    "[\n",
    "  {\n",
    "    \"name\": \"get_coordinates\",\n",
    "    \"description\": \"Get latitude and longitude for a city.\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"city_name\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"The name of the city for which to get coordinates.\"\n",
    "        }\n",
    "      },\n",
    "      \"required\": [\n",
    "        \"city_name\"\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get current weather information for a given latitude and longitude.\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"latitude\": {\n",
    "          \"type\": \"number\",\n",
    "          \"description\": \"The latitude of the location.\"\n",
    "        },\n",
    "        \"longitude\": {\n",
    "          \"type\": \"number\",\n",
    "          \"description\": \"The longitude of the location.\"\n",
    "        }\n",
    "      },\n",
    "      \"required\": [\n",
    "        \"latitude\",\n",
    "        \"longitude\"\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "]\n",
    "\n",
    "If you decide to invoke one or more functions, you MUST output a LIST  of objects, where each object is in the format:\n",
    "{\"name\": \"function_name\", \"parameters\": {\"argument_name1\": \"value1\", \"argument_name2\": \"value2\"}}\n",
    "\n",
    "For example:\n",
    "To make a single tool call you should output: [{\"name\": \"tool_A\", \"parameters\": {\"arg\": \"value\"}}]\n",
    "To make multiple tool calls you should output: [{\"name\": \"tool_A\", \"parameters\": {\"arg\": \"value\"}}, {\"name\": \"tool_B\", \"parameters\": {\"arg\": \"other_value\"}}]\n",
    "\n",
    "Remember: \n",
    "- Once you make a tool call, the response will be fed back to you.\n",
    "- Once you do not need to make any more tool calls - you can output the final answer.\n",
    "- Plan the sequence of your tool calls appropriately.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pydantic import BaseModel\n",
    "class Response(BaseModel):\n",
    "    \"\"\"Response schema for the thinking models\"\"\"\n",
    "    thoughts: str\n",
    "    answer: str\n",
    "\n",
    "def make_messages(query, system_prompt=SYSTEM_PROMPT1):\n",
    "    \"\"\"Make messages for the OpenAI API\"\"\"\n",
    "    \n",
    "    return [{\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": query}]\n",
    "    \n",
    "    \n",
    "def split_thoughts_and_answer(text):\n",
    "    # Extract thoughts from within <think>...</think>\n",
    "    thoughts_match = re.search(r\"<think>\\n?(.*?)</think>\", text, re.DOTALL)\n",
    "    thoughts = thoughts_match.group(1).strip() if thoughts_match else \"\"\n",
    "\n",
    "    # Extract the answer (everything after </think>)\n",
    "    answer_start = text.find(\"</think>\")\n",
    "    answer = text[answer_start + len(\"</think>\"):].strip()\n",
    "    \n",
    "    return {\"thoughts\": thoughts, \"answer\": answer}\n",
    "\n",
    "\n",
    "def ask_ollama_with_function_calling(messages):\n",
    "    \"\"\"Ask the OpenAI API with function calling\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen3:4b\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    \n",
    "    parsed_response = split_thoughts_and_answer(content)\n",
    "    \n",
    "    return Response(**parsed_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = ask_ollama_with_function_calling(make_messages(\"what is the weather in new york?\"))\n",
    "print(\"thoughts: \", resp.thoughts)\n",
    "print(\"-\"*100)\n",
    "print(\"answer: \", resp.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "# Check if the response is a valid tool call\n",
    "def is_response_valid_tool_call(response):\n",
    "    \"\"\"Check if the response is a valid tool call and return the parsed list, or False.\"\"\"\n",
    "    # Strip code block markers if present\n",
    "    if response.startswith(\"```json\") and response.endswith(\"```\"):\n",
    "        response = response[len(\"```json\"): -len(\"```\")].strip()\n",
    "    \n",
    "    # Try to parse the response as JSON\n",
    "    try:\n",
    "        tool_calls = json.loads(response)\n",
    "        if isinstance(tool_calls, list) and all(\n",
    "            isinstance(call, dict) and 'name' in call and 'parameters' in call for call in tool_calls\n",
    "        ):\n",
    "            return tool_calls\n",
    "        else:\n",
    "            return False\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# Create a tool response to be appended to the messages\n",
    "def create_tool_response(function_name, parameters, function_response):\n",
    "    \"\"\"Create a tool response\"\"\"\n",
    "    return f\"Function {function_name} called with parameters {parameters} and returned {function_response}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TURNS = 5\n",
    "AVAILABLE_FUNCTIONS = {\n",
    "    \"get_coordinates\": get_coordinates,\n",
    "    \"get_weather\": get_weather\n",
    "}\n",
    "def simple_loop(query, max_turns = MAX_TURNS):\n",
    "    messages = make_messages(query, SYSTEM_PROMPT1)\n",
    "    for i in range(max_turns):\n",
    "        completion_response = ask_ollama_with_function_calling(messages)\n",
    "        print(\"-\"*100)\n",
    "        print(\"Turn: \", i+1)\n",
    "        print(\"thoughts: \", completion_response.thoughts)\n",
    "        print(\"answer: \", completion_response.answer)\n",
    "        response = completion_response.answer\n",
    "        tool_calls_requested = is_response_valid_tool_call(response)\n",
    "        if not tool_calls_requested:\n",
    "            return response\n",
    "        else:\n",
    "            print(f\"Tool calls requested in turn {i+1}:\")\n",
    "            messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "            for tool_call in tool_calls_requested:\n",
    "                function_name = tool_call.get(\"name\")\n",
    "                parameters = tool_call.get(\"parameters\", {})\n",
    "                print(f\" Function name: {function_name}\")\n",
    "                print(f\" Parameters: {parameters}\")\n",
    "                if function_name in AVAILABLE_FUNCTIONS:\n",
    "                    function_to_call = AVAILABLE_FUNCTIONS[function_name]\n",
    "                    function_response = function_to_call(**parameters)\n",
    "                    messages.append({\"role\": \"user\", \"content\": create_tool_response(function_name, parameters, function_response)})\n",
    "                else:\n",
    "                    raise ValueError(f\"Function {function_name} not found\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_loop(\"what is the weather in visakhapatnam?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_loop(\"what is the weather in new york?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
